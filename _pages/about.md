---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- <span class='anchor' id='about-me'></span>
{% include_relative includes/intro.md %} -->

<span class='anchor' id='about-me'></span>
I am a 1st year Ph.D. student at the [National Engineering Research Center of Robot Visual Perception and Control Technology](http://robot.hnu.edu.cn/) of [Hunan University](https://www.hnu.edu.cn/), supervised by [Prof. Wei Sun](http://eeit.hnu.edu.cn/info/1281/4511.htm).

My research focuses on 3D computer vision, deep learning, and their applications for robotic manipulation. Specifically, I have worked on category-level 6D object pose estimation, and instance-level 6D object pose tracking. Subsequent research focuses include: label-efficient learning for generalized 6D object pose estimation and tracking. I was motivated to conduct this doctoral research due to my passion for realizing intelligent perception and autonomous manipulation of robots in 3D space.

# üî• News
- *2023.02*: &nbsp;üéâüéâ One paper is accepted by IEEE T-II!
- *2022.06*: &nbsp;üéâüéâ One paper is accepted by IEEE T-CSVT! 

# üìù Publications 
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE TII 2023</div><img src='images/paper2_512x512.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[Robotic Continuous Grasping System by Shape Transformer-Guided Multi-Object Category-Level 6D Pose Estimation](https://ieeexplore.ieee.org/abstract/document/10043016)\\
**Jian Liu**, Wei Sun, Chongpei Liu, Xing Zhang, Qiang Fu
- The GSENet is proposed to identify the global shape of an object category. It can effectively use the global and local features of the intra-class known object‚Äôs 3D model by residual connection and max-pooling. The global shape can be used as the prior information of intra-class known object.
- We propose a transformer-guided shape reconstruction network to reconstruct the NOCS shape of intra-class known object, which can fully use the prior feature, current observation feature, and their feature difference by internal self-attention, as well as strengthen their correlation by mutual cross-attention. By doing so, the shape variation can be explicitly highlighted.
</div></div>
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE TCSVT 2022</div><img src='images/paper1_512x512.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[HFF6D: Hierarchical Feature Fusion Network for Robust 6D Object Pose Tracking](https://ieeexplore.ieee.org/abstract/document/9792223)\\
**Jian Liu**, Wei Sun, Chongpei Liu, Xing Zhang, Shimeng Fan, Wei Wu
- We propose a light-weight and robust hierarchical feature fusion network for 6D object pose tracking. It can establish sufficient spatial-temporal information interaction between adjacent frames, thereby improving the accuracy of relative pose estimation.
- We propose a novel subtraction feature fusion module with attention mechanism to leverage feature subtraction during feature fusion. It explicitly highlights the feature differences between adjacent frames, thus improving the robustness of relative pose estimation in challenging scenes.
</div></div>
 
# üíª Projects
<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='images/project1_512x512.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[**Robotic Continuous Grasping System**](https://github.com/CNJianLiu/6D-CLGrasp) (Demo can be seen through [link1](https://www.bilibili.com/video/BV16M4y1Q7CD) or [link2](https://youtu.be/ZeGN6_DChuA))
- We build an end-to-end robotic continuous grasping system, which achieves high-accuracy 6D pose estimation for multiple intra-class unknown objects and highefficiency robotic grasping in 3D space. For continuous grasping, we propose a low-computation and effective grasping strategy based on the pre-defined vector orientation, and develop a GUI for monitoring and control.
</div></div>

# üéñ Honors and Awards
- *2018.11* The National First Prize in "Higher Education Society Cup" National Undergraduate Mathematical Contest in Modeling (Top 1.5 %).
- *2019.08* The National Second Prize in "RoboMaster2019" National Undergraduate Robotics Competition (Hosted by DJI-Innovations).
- *2018.06* Hong Kong "Zhong Huiming" Social Scholarship.

<!-- # üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

<!-- # üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->

<!-- {% include_relative includes/news.md %}

{% include_relative includes/pub.md %}

{% include_relative includes/honers.md %}

{% include_relative includes/others.md %}
 -->
